{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HandGesture",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPweXfEs/xdfW3dyAhbvk+D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zero-tanveer/shurjo042.github.io/blob/master/HandGesture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C0oho4eQbeU"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeCsx_Nvzq9J"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YBvUCtC0IN4"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1LY2kUaXY62IxGXsKziS-TZsxBnIFwCHK'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('kaggle.json') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrPb-5bQ1ixt"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_05U2nX2Xxi"
      },
      "source": [
        "!kaggle datasets download -d toxicmender/20bn-jester"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og8U32tg4aFf"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"20bn-jester.zip\"\n",
        "\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkr8HXLjTe7F"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "import seaborn as sbn\n",
        "import matplotlib.image as img\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUdltNd8UYg5"
      },
      "source": [
        "**Making smaller set**\n",
        "\n",
        "The classes (labels) we want to use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkGIU_dUUSm7"
      },
      "source": [
        "LABELS = {\n",
        "    \"Swiping Right\": 0,\n",
        "    \"Swiping Left\": 1,\n",
        "    \"No gesture\": 2,\n",
        "    \"Thumb Up\": 3,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85tV1h3SUtPx"
      },
      "source": [
        "**Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNga_mEAU1fg"
      },
      "source": [
        "BASE_PATH = '/content'\n",
        "TRAIN_DATA_CSV = BASE_PATH + '/Train.csv'\n",
        "TEST_DATA_CSV = BASE_PATH + '/Test.csv'\n",
        "VAL_DATA_CSV = BASE_PATH + '/Validation.csv'\n",
        "\n",
        "TRAIN_SAMPLES_PATH = BASE_PATH + '/Train/'\n",
        "TEST_SAMPLES_PATH = BASE_PATH + '/Test/'\n",
        "VAL_SAMPLES_PATH = BASE_PATH + '/Validation/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYv9_PEiVFj9"
      },
      "source": [
        "Training targets, you can use your custom csv file if you already created it before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzLJn2DHVIBG"
      },
      "source": [
        "targets = pd.read_csv(TRAIN_DATA_CSV)\n",
        "targets = targets[targets['label'].isin(LABELS.keys())]\n",
        "targets['label'] = targets['label'].map(LABELS)\n",
        "targets = targets[['video_id', 'label']]\n",
        "targets = targets.reset_index()\n",
        "targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1qk_6lOWhhv"
      },
      "source": [
        "Validation targets, you can use your custom csv file if you already created it before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slnOMvUiWkAs"
      },
      "source": [
        "targets_validation = pd.read_csv(VAL_DATA_CSV)\n",
        "targets_validation = targets_validation[targets_validation['label'].isin(LABELS.keys())]\n",
        "targets_validation['label'] = targets_validation['label'].map(LABELS)\n",
        "targets_validation = targets_validation[['video_id', 'label']]\n",
        "targets_validation = targets_validation.reset_index()\n",
        "targets_validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AfjqtBBWsUh"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTTdLoyWWuhw"
      },
      "source": [
        "def rgb2gray(rgb):\n",
        "    \"\"\"\n",
        "    Converts numpy array of RGB to grayscale\n",
        "    \"\"\"\n",
        "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPi0TFjqW0MC"
      },
      "source": [
        "def resize_frame(frame):\n",
        "    \"\"\"\n",
        "    Resizes frames to (64, 64)\n",
        "    \"\"\"\n",
        "    frame = img.imread(frame)\n",
        "    frame = cv2.resize(frame, (64, 64))\n",
        "    return frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2uo2TNiW6yv"
      },
      "source": [
        "The videos do not have the same number of frames, here we try to unify."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzHisiMpW77x"
      },
      "source": [
        "hm_frames = 30 # number of frames\n",
        "def get_unify_frames(path):\n",
        "    \"\"\"\n",
        "    Unifies number of frames for each training\n",
        "    \"\"\"\n",
        "    offset = 0\n",
        "    # pick frames\n",
        "    frames = os.listdir(path)\n",
        "    frames_count = len(frames)\n",
        "    # unify number of frames \n",
        "    if hm_frames > frames_count:\n",
        "        # duplicate last frame if video is shorter than necessary\n",
        "        frames += [frames[-1]] * (hm_frames - frames_count)\n",
        "    elif hm_frames < frames_count:\n",
        "        # If there are more frames, then sample starting offset\n",
        "        # diff = (frames_count - hm_frames)\n",
        "        # offset = diff-1 \n",
        "        frames = frames[0:hm_frames]\n",
        "    return frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgdpJj50XIpc"
      },
      "source": [
        "Adjust data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So1A44SCXKjx"
      },
      "source": [
        "# Adjust training data\n",
        "train_targets = [] # training targets \n",
        "test_targets = [] # testing targets\n",
        "\n",
        "new_frames = [] # training data after resize & unify\n",
        "new_frames_test = [] # testing data after resize & unify\n",
        "\n",
        "for idx, row in tqdm(targets.iterrows(), total=len(targets)):\n",
        "    if idx % 4 == 0:\n",
        "        continue\n",
        "    \n",
        "    partition = [] # one training\n",
        "    # Frames in each folder\n",
        "    frames = get_unify_frames(TRAIN_SAMPLES_PATH + str(row['video_id']))\n",
        "    if len(frames) == hm_frames: # just to be sure\n",
        "        for frame in frames:\n",
        "            frame = resize_frame(TRAIN_SAMPLES_PATH + str(row['video_id']) + '/' + frame)\n",
        "            partition.append(rgb2gray(frame))\n",
        "            if len(partition) == 15: # partition each training on two trainings.\n",
        "                if idx % 6 == 0:\n",
        "                    new_frames_test.append(partition) # append each partition to training data\n",
        "                    test_targets.append(row['label'])\n",
        "                else:\n",
        "                    new_frames.append(partition) # append each partition to test data\n",
        "                    train_targets.append(row['label'])\n",
        "                partition = []\n",
        "\n",
        "train_data = np.asarray(new_frames, dtype=np.float16)\n",
        "del new_frames[:]\n",
        "del new_frames\n",
        "\n",
        "test_data = np.asarray(new_frames_test, dtype=np.float16)\n",
        "del new_frames_test[:]\n",
        "del new_frames_test\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5ChQwzCX9Bx"
      },
      "source": [
        "# we do the same for the validation data\n",
        "cv_targets = []\n",
        "new_frames_cv = []\n",
        "for idx, row in tqdm(targets_validation.iterrows(), total=len(targets_validation)):\n",
        "    if idx % 4 == 0:\n",
        "        continue\n",
        "\n",
        "    partition = []\n",
        "    # Frames in each folder\n",
        "    frames = get_unify_frames(VAL_SAMPLES_PATH+str(row[\"video_id\"]))\n",
        "    for frame in frames:\n",
        "        frame = resize_frame(VAL_SAMPLES_PATH+str(row[\"video_id\"])+'/'+frame)\n",
        "        partition.append(rgb2gray(frame))\n",
        "        if len(partition) == 15:\n",
        "            new_frames_cv.append(partition)\n",
        "            cv_targets.append(row['label'])\n",
        "            partition = []\n",
        "                \n",
        "cv_data = np.array(new_frames_cv, dtype=np.float16)\n",
        "del new_frames_cv[:]\n",
        "del new_frames_cv\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdWcwjhIX-73"
      },
      "source": [
        "print(f\"Training = {len(train_data)}/{len(train_targets)} samples/labels\")\n",
        "print(f\"Test = {len(test_data)}/{len(test_targets)} samples/labels\")\n",
        "print(f\"Validation = {len(cv_data)}/{len(cv_targets)} samples/labels\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "truQO_5zYX62"
      },
      "source": [
        "Feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDplRZ2OYZZb"
      },
      "source": [
        "# Normalisation: training\n",
        "print('old mean', train_data.mean())\n",
        "\n",
        "scaler = StandardScaler(copy=False)\n",
        "scaled_images  = scaler.fit_transform(train_data.reshape(-1, 15*64*64))\n",
        "del train_data\n",
        "print('new mean', scaled_images.mean())\n",
        "\n",
        "scaled_images  = scaled_images.reshape(-1, 15, 64, 64, 1)\n",
        "print(scaled_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYZGll5DYiQA"
      },
      "source": [
        "# Normalisation: test\n",
        "print('old mean', test_data.mean())\n",
        "\n",
        "scaler = StandardScaler(copy=False)\n",
        "scaled_images_test = scaler.fit_transform(test_data.reshape(-1, 15*64*64))\n",
        "del test_data\n",
        "print('new mean', scaled_images_test.mean())\n",
        "\n",
        "scaled_images_test = scaled_images_test.reshape(-1, 15, 64, 64, 1)\n",
        "print(scaled_images_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a97zQT9BYj-S"
      },
      "source": [
        "# Normalisation: validation\n",
        "print('old mean', cv_data.mean())\n",
        "\n",
        "scaler = StandardScaler(copy=False)\n",
        "scaled_images_cv  = scaler.fit_transform(cv_data.reshape(-1, 15*64*64))\n",
        "del cv_data\n",
        "print('new mean',scaled_images_cv.mean())\n",
        "\n",
        "scaled_images_cv  = scaled_images_cv.reshape(-1, 15, 64, 64, 1)\n",
        "print(scaled_images_cv.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3B5ObuvZGtT"
      },
      "source": [
        "del scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EomvawMeZobc"
      },
      "source": [
        "**Make sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8400WEXZrh4"
      },
      "source": [
        "y_train = np.array(train_targets, dtype=np.int8)\n",
        "y_test = np.array(test_targets, dtype=np.int8)\n",
        "y_val = np.array(cv_targets, dtype=np.int8)\n",
        "del train_targets\n",
        "del test_targets\n",
        "del cv_targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVoLhKMfZxNB"
      },
      "source": [
        "x_train = scaled_images\n",
        "x_test = scaled_images_test\n",
        "x_val = scaled_images_cv\n",
        "del scaled_images\n",
        "del scaled_images_test\n",
        "del scaled_images_cv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqbo7LOFZ3ay"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5vMknt-Z96u"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKIJgyeraAQN"
      },
      "source": [
        "class Conv3DModel(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    \n",
        "        # Convolutions\n",
        "        self.conv1 = tf.compat.v2.keras.layers.Conv3D(32, (3, 3, 3), activation='relu', name=\"conv1\", data_format='channels_last')\n",
        "        self.pool1 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2), data_format='channels_last')\n",
        "        self.conv2 = tf.compat.v2.keras.layers.Conv3D(64, (3, 3, 3), activation='relu', name=\"conv2\", data_format='channels_last')\n",
        "        self.pool2 = tf.keras.layers.MaxPool3D(pool_size=(2, 2,2), data_format='channels_last')\n",
        "        self.conv3 = tf.compat.v2.keras.layers.Conv3D(128, (3, 3, 3), activation='relu', name=\"conv3\", data_format='channels_last')\n",
        "        self.pool3 = tf.keras.layers.MaxPool3D(pool_size=(2, 2,2), data_format='channels_last')\n",
        "   \n",
        "        # LSTM & Flatten\n",
        "        self.convLSTM =tf.keras.layers.ConvLSTM2D(40, (3, 3))\n",
        "        self.flatten =  tf.keras.layers.Flatten(name=\"flatten\")\n",
        "\n",
        "        # Dense layers\n",
        "        self.d1 = tf.keras.layers.Dense(128, activation='relu', name=\"d1\")\n",
        "        self.out = tf.keras.layers.Dense(4, activation='softmax', name=\"output\")\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.convLSTM(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.d1(x)\n",
        "        return self.out(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj5fgebvaTGX"
      },
      "source": [
        "model = Conv3DModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKg1Fvl5aymc"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49nSiiv8bMc2"
      },
      "source": [
        "**Start Running**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOwoJR0DbUJ9"
      },
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    batch_size=80,\n",
        "                    epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJRmzJlS4ziP"
      },
      "source": [
        "[loss, acc] = model.evaluate(x_test,y_test,verbose=1)\n",
        "print(\"Accuracy:\" + str(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi6Mg0z96TCh"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLn8NwFB6kbD"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCJkJPCXitSi"
      },
      "source": [
        "model.save_weights('/w.tf', save_format='tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdHxpXXVnG7G"
      },
      "source": [
        "**Make Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DGZXAzonL9J"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYgTKKCknZHc"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iww1i12XnaQU"
      },
      "source": [
        "np.unique(y_test, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gncuNhVlnd29"
      },
      "source": [
        "Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMssBvRkngZ1"
      },
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtRY1NNXnkXC"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY4-oRFwnp4A"
      },
      "source": [
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFdTw0VtnsmZ"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-Ru4DsPny8K"
      },
      "source": [
        "**Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6bf0sinnwVS"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3ep55lLn__Y"
      },
      "source": [
        "labels = list(LABELS.keys())\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnUaOdploC9T"
      },
      "source": [
        "**1. Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQQZcc9roGe_"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
        "df_cm = pd.DataFrame(cm, range(4), range(4))\n",
        "plt.figure(figsize=(15,15))\n",
        "sbn.set(font_scale=1.4) # for label size\n",
        "sbn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, xticklabels=labels, yticklabels=labels)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h05qbbSLoP8q"
      },
      "source": [
        "**2. Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDYAoht9oR2N"
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptSNcutSoaA_"
      },
      "source": [
        "**3. Precision**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF7RDrSRoYNJ"
      },
      "source": [
        "precision_score(y_test, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMN-jZmBoqxP"
      },
      "source": [
        "**4. Recall**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyXBO4juotSL"
      },
      "source": [
        "recall_score(y_test, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE5NVuQVo0hE"
      },
      "source": [
        "**5. F1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRBmZhRyowce"
      },
      "source": [
        "f1_score(y_test, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}